{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import platform\n",
        "import gc\n",
        "import sys\n",
        "import argparse\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from joblib import Parallel, delayed\n",
        "import re\n",
        "import random\n",
        "import requests\n",
        "import urllib.request\n",
        "import json\n",
        "from copy import deepcopy\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "import transformers\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, TrainingArguments, AutoModelForCausalLM, BitsAndBytesConfig, PreTrainedTokenizerFast\n",
        "from datasets import load_dataset\n",
        "from trl import DPOTrainer, SFTTrainer\n",
        "import bitsandbytes as bnb\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "from typing import Optional, Dict, Sequence\n",
        "from Korpora import Korpora\n",
        "from Korpora import KowikiTextKorpus, KorNLIKorpus\n",
        "# from googletrans import Translator\n",
        "from dask import bag, diagnostics\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "mrlA0T8mk8nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_system_specs():\n",
        "    # Check if CUDA is available\n",
        "    is_cuda_available = torch.cuda.is_available()\n",
        "    print(\"CUDA Available:\", is_cuda_available)\n",
        "# Get the number of available CUDA devices\n",
        "    num_cuda_devices = torch.cuda.device_count()\n",
        "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
        "    if is_cuda_available:\n",
        "        for i in range(num_cuda_devices):\n",
        "            # Get CUDA device properties\n",
        "            device = torch.device('cuda', i)\n",
        "            print(f\"--- CUDA Device {i} ---\")\n",
        "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
        "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
        "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
        "    # Get CPU information\n",
        "    print(\"--- CPU Information ---\")\n",
        "    print(\"Processor:\", platform.processor())\n",
        "    print(\"System:\", platform.system(), platform.release())\n",
        "    print(\"Python Version:\", platform.python_version())\n",
        "print_system_specs()"
      ],
      "metadata": {
        "id": "5l0uINmZk7Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "o-fokCgZk6G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QF_pOTO8k5Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load to Data\n",
        "data_location = '/content/drive/MyDrive/llm'\n",
        "data_path = Path(data_location)\n",
        "\n",
        "train = pd.read_csv(data_path / 'train.csv')"
      ],
      "metadata": {
        "id": "U33QJETmk3UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  parser = argparse.ArgumentParser(description = 'paul77ms')\n",
        "  parser.add_argument('--st_model_name', default = None, type = str)\n",
        "  parser.add_argument('--tok_model_name', default = None, type = str)\n",
        "  parser.add_argument('--model_name', default = None, type = str)\n",
        "  parser.add_argument('--optimizer', default = 'adamw', type = str)\n",
        "  parser.add_argument('--learning_rate', default = 1e-4, type = float)\n",
        "  parser.add_argument('--batch_size', default = 32, type = int)\n",
        "  parser.add_argument('--epochs', default = 10, type = int)\n",
        "  parser.add_argument('--seed', default = 0, type = int)\n",
        "  parser.add_argument('--shuffle', default = True, type = bool)\n",
        "  parser.add_argument('--num_workers', default = 0, type = int)\n",
        "  args = parser.parse_args('')\n",
        "\n",
        "  OPTIMIZER = args.optimizer\n",
        "  BATCH_SIZE = args.batch_size\n",
        "  LEARNING_RATE = args.learning_rate\n",
        "  EPOCHS = args.epochs\n",
        "  SEED = args.seed\n",
        "  SHUFFLE = args.shuffle\n",
        "  NUM_WORKERS = args.num_workers\n",
        "\n",
        "\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  def Seed_Fixer(seed=SEED):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    pl.seed_everything(SEED)\n",
        "\n",
        "  Seed_Fixer()\n",
        "\n",
        "  # Sentence Transformer\n",
        "  # https://github.com/jhgan00/ko-sentence-transformers\n",
        "  args.st_model_name = 'nli'\n",
        "  if 'ko-sroberta-multitask' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('jhgan/ko-sroberta-multitask').to(device)\n",
        "  elif 'ko-sbert-multitask' in args.st_model_name:\n",
        "    ST_ModEL = SentenceTransformer('jhgan/ko-sbert-multitask').to(device)\n",
        "  elif 'nli' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('jhgan/ko-sbert-nli').to(device)\n",
        "  elif 'sts' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('jhgan/ko-sbert-sts').to(device)\n",
        "  elif 'klue' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('klue/robert-base').to(device)\n",
        "  elif 'klue_small' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('klue-roberta-small-nli-sts').to(device)\n",
        "  elif 'huffon' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('Huffon/sentence-klue-roberta-base').to(device)\n",
        "  elif 'bert' in args.st_model_name:\n",
        "    ST_MODEL = SentenceTransformer('kykim/bert-kor-base').to(device)\n",
        "\n",
        "  # Inference Sentence Transformer\n",
        "  INFERENCE_ST_MODEL = SentenceTransformer('distiluse-base-multilingual-cased-v1').to(device)\n",
        "\n",
        "  # Tokenizer & Large Language Model (LLM)\n",
        "  args.model_name = 'yanolja'\n",
        "  if 'mistral' in args.model_name:\n",
        "    model_name = 'davidkim205/komt-mistral-7b-v1'\n",
        "  elif 'upstage_solar' in args.model_name:\n",
        "    model_name = 'Upstage/SOLAR-10.7B-v1.0'\n",
        "  elif 'solar2' in args.model_name:\n",
        "    model_name = 'Edentns/DataVortexS-10.7B-dpo-v1.0'\n",
        "  elif 'solar1' in args.model_name:\n",
        "    model_name = 'LDCC/LDCC-SOLAR-10.7B'\n",
        "  elif 'koalpaca' in args.model_name:\n",
        "    model_name = 'mncai/Mistral-7B-v0.1-alpaca-1k'\n",
        "  elif 'cokal' in args.model_name:\n",
        "    model_name = 'HumanF-MarkrAI/COKAL-DPO-13b-v2'\n",
        "  elif 'koalpaca_5.8b' in args.model_name:\n",
        "    model_name = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
        "  elif 'qlora_koalpaca_12.8b' in args.model_name:\n",
        "    model_name = 'beomi/qlora-koalpaca-polyglot-12.8b-50step'\n",
        "  elif 'koalpaca_12.8b' in args.model_name:\n",
        "    model_name = 'EleutherAI/polyglot-ko-12.8b'\n",
        "  elif 'yanolja' in args.model_name:\n",
        "    model_name = 'yanolja/KoSOLAR-10.7B-v0.2'"
      ],
      "metadata": {
        "id": "3fOzuRcfkwtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i99iZ6gukkKQ"
      },
      "outputs": [],
      "source": [
        "# SentanceTransformer\n",
        "\n",
        "def encode_question_sentence_transformer(df, model, device):\n",
        "  question1 = '질문_1'\n",
        "  question2 = '질문_2'\n",
        "  embeddings = []\n",
        "\n",
        "  for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    sentences = row[question1] + ' ' + row[question2]\n",
        "    sentence_embeddings = model.encode(sentences, device=device).astype(np.float16)\n",
        "    embeddings.append(sentence_embeddings)\n",
        "\n",
        "  return np.array(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = encode_question_sentence_transformer(train, ST_MODEL, device)"
      ],
      "metadata": {
        "id": "YpOg5T6EkoRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Ranking\n",
        "\n",
        "def rerank_answers(df, question_embeddings, model, device):\n",
        "  answers = ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']\n",
        "  reranked_df = df.copy()\n",
        "\n",
        "  for q_question_embedding_idx in tqdm(range(len(question_embeddings) // 2)):\n",
        "    answer_embeddings = model.encode(reranked_df.iloc[q_question_embedding_idx * 2][answers].tolist(), device=device)\n",
        "\n",
        "    for q_idx in range(2):\n",
        "      q_question_embedding = question_embeddings[q_question_embedding_idx * 2 + q_idx].reshape(1, -1)\n",
        "\n",
        "      similarities = cosine_similarity(q_question_embedding, answer_embeddings)[0]\n",
        "      reranked_answers = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
        "      reranked_answers_indices = [idx for idx, _ in reranked_answers]\n",
        "\n",
        "      for idx, answer in enumerate(answers):\n",
        "        rank_col = f'{answer}_rank'\n",
        "        reranked_df.at[q_question_embedding_idx * 2 + q_idx, rank_col] = reranked_answers_indices[idx] + 1\n",
        "\n",
        "  return reranked_df"
      ],
      "metadata": {
        "id": "5mqoyvIdkquz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_reranked = rerank_answers(train, embs, ST_MODEL, device)"
      ],
      "metadata": {
        "id": "CiH2pZ0Qkspv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Ranking Filtered Answers Augmentation\n",
        "\n",
        "N = 3\n",
        "for idx in range(N):\n",
        "  train_reranked[f'reranked{idx+1}'] = np.nan\n",
        "reranked_columns = train_reranked.columns[train_reranked.columns.str.endswith('_rank')]\n",
        "\n",
        "for rank_col in reranked_columns:\n",
        "  answer_col = rank_col.replace('_rank', '')\n",
        "  for idx in range(N):\n",
        "    mask = train_reranked[rank_col] == idx+1\n",
        "\n",
        "    train_reranked.loc[train_reranked[mask][answer_col].index, f'reranked{idx+1}'] = train_reranked[mask][answer_col]"
      ],
      "metadata": {
        "id": "4mT1-lKqkuFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_reranked.head()"
      ],
      "metadata": {
        "id": "SXaJhNqvkvFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}